[
  "This is the core process of training, tuning, and evaluating your model, as described in the previous section. It includes establishing MLOps. Machine learning operations (MLOps) are a set of practices that automate and simplify machine learning (ML) workflows and deployments. They unify ML development with deployment and operations. For example, you create a CI/CD pipeline that automates the build, train, and release to staging and production environments.",
  "Build, train, and deploy ML models at scale",
  "Enhance and visualize deep learning applications with ML tools",
  "Build ML applications that train quickly and run virtually anywhere",
  "Model development and deployment This is the core process of training, tuning, and evaluating your model, as described in the previous section. It includes establishing MLOps. Machine learning operations (MLOps) are a set of practices that automate and simplify machine learning (ML) workflows and deployments. They unify ML development with deployment and operations. For example, you create a CI/CD pipeline that automates the build, train, and release to staging and production environments.",
  "Model development and deployment This is the core process of training, tuning, and evaluating your model, as described in the previous section. It includes establishing MLOps. Machine learning operations (MLOps) are a set of practices that automate and simplify machine learning (ML) workflows and deployments. They unify ML development with deployment and operations. For example, you create a CI/CD pipeline that automates the build, train, and release to staging and production environments.",
  "How can AWS machine learning help? AWS puts machine learning in the hands of every developer, data scientist, and business user. AWS Machine Learning services provide high-performing, cost-effective, and scalable infrastructure to meet business needs. Get started with Machine Learning on AWS by creating a free account today! Service Amazon SageMaker AI Build, train, and deploy ML models at scale View service Service AWS Deep Learning AMIs Quickly build scalable, secure deep learning applications in preconfigured environments View service Service AWS Deep Learning Containers Quickly deploy deep learning environments with optimized, prepackaged container images View service Framework Hugging Face on Amazon SageMaker Train and deploy Hugging Face models in minutes View framework Framework TensorFlow on AWS Enhance and visualize deep learning applications with ML tools View framework Framework PyTorch on AWS Leverage a highly performant, scalable, and enterprise-ready PyTorch experience on AWS View framework Framework Apache MXNet on AWS Build ML applications that train quickly and run virtually anywhere View framework Framework Jupyter on AWS A secure, scalable, and collaborative Jupyter experience on AWS View framework",
  "Service Amazon SageMaker AI Build, train, and deploy ML models at scale View service Service AWS Deep Learning AMIs Quickly build scalable, secure deep learning applications in preconfigured environments View service Service AWS Deep Learning Containers Quickly deploy deep learning environments with optimized, prepackaged container images View service Framework Hugging Face on Amazon SageMaker Train and deploy Hugging Face models in minutes View framework Framework TensorFlow on AWS Enhance and visualize deep learning applications with ML tools View framework Framework PyTorch on AWS Leverage a highly performant, scalable, and enterprise-ready PyTorch experience on AWS View framework Framework Apache MXNet on AWS Build ML applications that train quickly and run virtually anywhere View framework Framework Jupyter on AWS A secure, scalable, and collaborative Jupyter experience on AWS View framework",
  "ML is short for Machine Learning which is a branch of artificial intelligence (AI) and computer science that leverages data and algorithms to enable AI systems to learn and improve in a manner similar to humans, progressively enhancing their accuracy over time.",
  "ML is short for Machine Learning which is a branch of artificial intelligence (AI) and computer science that leverages data and algorithms to enable AI systems to learn and improve in a manner similar to humans, progressively enhancing their accuracy over time.",
  "Artificial intelligence (AI) is an umbrella term for different strategies and techniques you can use to make machines more humanlike. AI includes everything from smart assistants like Alexa to robotic vacuum cleaners and self-driving cars. Machine learning (ML) is one among many other branches of AI. ML is the science of developing algorithms and statistical models that computer systems use to perform complex tasks without explicit instructions. The systems rely on patterns and inference instead. Computer systems use ML algorithms to process large quantities of historical data and identify data patterns. While machine learning is AI, not all AI activities are machine learning.",
  "Read about machine learning (ML) »",
  "Machine learning (ML) is a narrowly focused branch of artificial intelligence (AI). But both of these fields go beyond basic automation and programming to generate outputs based on complex data analysis.",
  "A property pricing ML algorithm, for example, applies knowledge of previous sales prices, market conditions, floor plans, and location to predict the price of a house.",
  "ML applications are also broad. They can include predictive machinery maintenance scheduling, dynamic travel pricing, insurance fraud detection, and retail demand forecasting.",
  "Machine learning (ML) is a specific branch of artificial intelligence (AI). ML has a limited scope and focus compared to AI. AI includes several strategies and technologies that are outside the scope of machine learning.",
  "On the other hand, the goal of ML is to have a machine analyze large volumes of data. The machine will use statistical models to identify patterns in the data and produce a result. The result has an associated probability of correctness or degree of confidence.",
  "Within ML, methods are divided into two broad categories: supervised and unsupervised learning. Supervised ML algorithms learn to solve problems using data values labeled input and output. Unsupervised learning is more exploratory and attempts to discover hidden patterns in unlabeled data.",
  "The process of building an ML solution typically involves two tasks:",
  "Data scientists select important data features and feed them into the model for training. They continuously refine the dataset with updated data and error checking. Data quality and variety improve the accuracy of the ML model.",
  "ML solutions require a dataset of several hundred data points for training, plus sufficient computational power to run. Depending on your application and use case, a single server instance or a small server cluster may be sufficient.",
  "However, it’s important to note that both prebuilt AI and ML functions are available. You can integrate them into your application through APIs without the need for additional resources.",
  "If you want to use artificial intelligence (AI) or machine learning (ML), start by defining the problems you want to solve or research questions you want to explore. Once you identify the problem space, you can determine the appropriate AI or ML technology to solve it. It’s important to consider the type and size of training data available and preprocess the data before you start.",
  "AI is broad term for machine-based applications that mimic human intelligence. Not all AI solutions are ML.",
  "ML is an artificial intelligence methodology. All ML solutions are AI solutions.",
  "ML is best for identifying patterns in large sets of data to solve specific problems.",
  "For ML, people manually select and extract features from raw data and assign weights to train the model.",
  "You train new or existing ML models for your specific use case. Prebuilt ML APIs are available.",
  "Amazon SageMaker is a complete platform to build your ML solutions from the ground up. SageMaker has a full suite of prebuilt machine learning models, storage and compute capabilities, and a fully managed environment.",
  "How can organizations use AI and ML?",
  "Some machine learning (ML) solutions apply to most organizations:",
  "Choose a preexisting ML strategy or model, such as linear regression or a decision tree",
  "What’s the difference between AI and Machine Learning? What are the similarities between AI and machine learning? Key differences: AI vs. machine learning What would an organization need to get started with AI and machine learning? How can organizations use AI and ML? Summary of differences: AI vs. machine learning How can AWS support your AI and machine learning requirements?",
  "What’s the difference between AI and Machine Learning? Artificial intelligence (AI) is an umbrella term for different strategies and techniques you can use to make machines more humanlike. AI includes everything from smart assistants like Alexa to robotic vacuum cleaners and self-driving cars. Machine learning (ML) is one among many other branches of AI. ML is the science of developing algorithms and statistical models that computer systems use to perform complex tasks without explicit instructions. The systems rely on patterns and inference instead. Computer systems use ML algorithms to process large quantities of historical data and identify data patterns. While machine learning is AI, not all AI activities are machine learning. Read about artifical intelligence (AI) » Read about machine learning (ML) » What are the similarities between AI and machine learning? Machine learning (ML) is a narrowly focused branch of artificial intelligence (AI). But both of these fields go beyond basic automation and programming to generate outputs based on complex data analysis. Humanlike problem-solving Artificial intelligence and machine learning (AI/ML) solutions are suited for complex tasks that generally involve precise outcomes based on learned knowledge. For instance, a self-driving AI car uses computer vision to recognize objects in its field of view and knowledge of traffic regulations to navigate a vehicle. A property pricing ML algorithm, for example, applies knowledge of previous sales prices, market conditions, floor plans, and location to predict the price of a house. Computer science fields Artificial intelligence and machine learning are fields of computer science that focus on creating software that analyzes, interprets, and comprehends data in complex ways. Scientists within these fields attempt to program a computer system to perform complex tasks that involve self-learning. A well-designed software will complete tasks either as fast as or faster than a person. Cross-industry applications There are applications of AI across all industries. You can use AI to optimize supply chains, predict sports outcomes, improve agricultural outcomes, and personalize skincare recommendations. ML applications are also broad. They can include predictive machinery maintenance scheduling, dynamic travel pricing, insurance fraud detection, and retail demand forecasting. Key differences: AI vs. machine learning Machine learning (ML) is a specific branch of artificial intelligence (AI). ML has a limited scope and focus compared to AI. AI includes several strategies and technologies that are outside the scope of machine learning. Here are some key differences between the two. Objectives The goal of any AI system is to have a machine complete a complex human task efficiently. Such tasks may involve learning, problem-solving, and pattern recognition. On the other hand, the goal of ML is to have a machine analyze large volumes of data. The machine will use statistical models to identify patterns in the data and produce a result. The result has an associated probability of correctness or degree of confidence. Methods The field of AI encompasses a variety of methods used to solve diverse problems. These methods include genetic algorithms, neural networks, deep learning, search algorithms, rule-based systems, and machine learning itself. Within ML, methods are divided into two broad categories: supervised and unsupervised learning. Supervised ML algorithms learn to solve problems using data values labeled input and output. Unsupervised learning is more exploratory and attempts to discover hidden patterns in unlabeled data. Implementations The process of building an ML solution typically involves two tasks: Select and prepare a training dataset Choose a preexisting ML strategy or model, such as linear regression or a decision tree Data scientists select important data features and feed them into the model for training. They continuously refine the dataset with updated data and error checking. Data quality and variety improve the accuracy of the ML model. Building an AI product is typically a more complex process, so many people choose prebuilt AI solutions to achieve their goals. These AI solutions have generally been developed after years of research, and developers make them available for integration with products and services through APIs. Requirements ML solutions require a dataset of several hundred data points for training, plus sufficient computational power to run. Depending on your application and use case, a single server instance or a small server cluster may be sufficient. Other intelligent systems may have varying infrastructure requirements, which depend on the task you want to accomplish and the computational analysis methodology you use. High-computing use cases require several thousand machines working together to achieve complex goals. However, it’s important to note that both prebuilt AI and ML functions are available. You can integrate them into your application through APIs without the need for additional resources. What would an organization need to get started with AI and machine learning? If you want to use artificial intelligence (AI) or machine learning (ML), start by defining the problems you want to solve or research questions you want to explore. Once you identify the problem space, you can determine the appropriate AI or ML technology to solve it. It’s important to consider the type and size of training data available and preprocess the data before you start. With on-demand cloud services, you can create, run, and manage AI. And learning functions can be created, run, and managed from the Amazon Web Services (AWS) Cloud. How can organizations use AI and ML? Some machine learning (ML) solutions apply to most organizations: Customer segmentation is where you segment customers via their behavior, preferences, and characteristics for further sales and marketing activities. Read how Lion Parcel uses AWS for customer segmentation. Fraud detection is where you triage and resolve unusual transactions that are discovered. Read how Luno uses AWS for fraud detection. Sentiment analysis is where customer feedback is incorporated to inform product strategy and marketing. Read how Zignal Labs uses AWS for sentiment analysis. And here are artificial intelligence (AI) solutions that apply to most organizations: Chatbots are suited for customer service inquiries and triaging. Read how MetroPlusHealth uses AWS for chatbots. Speech recognition is great for transcribing meetings into written minutes. Read how Epiq uses AWS for speech recognition. Computer vision works well for biometrics recognition systems. Read how PayEye uses AWS for computer vision. Summary of differences: AI vs. machine learning Artificial Intelligence Machine Learning What is it? AI is broad term for machine-based applications that mimic human intelligence. Not all AI solutions are ML. ML is an artificial intelligence methodology. All ML solutions are AI solutions. Best suited for AI is best for completing a complex human task with efficiency. ML is best for identifying patterns in large sets of data to solve specific problems. Methods AI may use a wide range of methods, like rule-based, neural networks, computer vision, and so on. For ML, people manually select and extract features from raw data and assign weights to train the model. Implementation AI implementation depends on the task. AI is often prebuilt and accessed via APIs. You train new or existing ML models for your specific use case. Prebuilt ML APIs are available. How can AWS support your AI and machine learning requirements? AWS offers a wide range of services to help you build, run, and integrate artificial intelligence and machine learning (AI/ML) solutions of any size, complexity, or use case. Amazon SageMaker is a complete platform to build your ML solutions from the ground up. SageMaker has a full suite of prebuilt machine learning models, storage and compute capabilities, and a fully managed environment. For AI, you can use AWS services to build your own AI solutions from scratch or integrate prebuilt artificial intelligence (AI) services into your solution.",
  "Streamline every step of the ML lifecycle with the most comprehensive set of services and purpose-built infrastructure",
  "AWS helps you innovate with machine learning (ML) at scale with the most comprehensive set of ML services, infrastructure, and deployment resources. From the world’s largest enterprises to emerging startups, more than 100,000 customers have chosen AWS machine learning services to solve business problems and drive innovation. With Amazon SageMaker, you can build, train, and deploy machine learning and foundation models at scale with infrastructure and purpose-built tools for each step of the ML lifecycle.",
  "Build, train, and deploy ML models at scale",
  "Enhance and visualize deep learning applications with ML tools",
  "Build ML applications that train quickly and run virtually anywhere",
  "Get high-performance GPU-based instances for graphics-intensive applications and ML inference",
  "Expand your ML skills by competing in the world’s first global autonomous racing league",
  "Learn how to use Amazon SageMaker to accomplish various ML lifecycle tasks",
  "Curated training resources for data scientists and ML engineers",
  "Build new ML skills in your organization using the same curriculum used at Amazon",
  "Machine learning on AWS AWS helps you innovate with machine learning (ML) at scale with the most comprehensive set of ML services, infrastructure, and deployment resources. From the world’s largest enterprises to emerging startups, more than 100,000 customers have chosen AWS machine learning services to solve business problems and drive innovation. With Amazon SageMaker, you can build, train, and deploy machine learning and foundation models at scale with infrastructure and purpose-built tools for each step of the ML lifecycle.",
  "Machine learning on AWS AWS helps you innovate with machine learning (ML) at scale with the most comprehensive set of ML services, infrastructure, and deployment resources. From the world’s largest enterprises to emerging startups, more than 100,000 customers have chosen AWS machine learning services to solve business problems and drive innovation. With Amazon SageMaker, you can build, train, and deploy machine learning and foundation models at scale with infrastructure and purpose-built tools for each step of the ML lifecycle.",
  "Resources to develop your machine learning skills Explore more machine learning training Resources AWS Solutions Library Browse curated solutions and guidance for common AI use cases Browse AI solutions library Hands-on experience AWS DeepRacer League Expand your ML skills by competing in the world’s first global autonomous racing league Get started Hands-on experience Amazon SageMaker Studio Lab Learn and experiment with ML Get started Hands-on experience Machine Learning Tutorials Learn how to use Amazon SageMaker to accomplish various ML lifecycle tasks Get started Training AI Courses for Machine Learning Engineers Curated training resources for data scientists and ML engineers Get started",
  "Resources AWS Solutions Library Browse curated solutions and guidance for common AI use cases Browse AI solutions library Hands-on experience AWS DeepRacer League Expand your ML skills by competing in the world’s first global autonomous racing league Get started Hands-on experience Amazon SageMaker Studio Lab Learn and experiment with ML Get started Hands-on experience Machine Learning Tutorials Learn how to use Amazon SageMaker to accomplish various ML lifecycle tasks Get started Training AI Courses for Machine Learning Engineers Curated training resources for data scientists and ML engineers Get started",
  "Build new ML skills in your organization using the same curriculum used at Amazon Get started",
  "What is Machine Learning (ML)?",
  "What is Machine Learning (ML)?",
  "Machine learning (ML) is a branch of artificial intelligence (AI) focused on enabling computers and machines to imitate the way that humans learn, to perform tasks autonomously, and to improve their performance and accuracy through experience and exposure to more data.",
  "What is machine learning? Machine learning (ML) is a branch of artificial intelligence (AI) focused on enabling computers and machines to imitate the way that humans learn, to perform tasks autonomously, and to improve their performance and accuracy through experience and exposure to more data. UC Berkeley breaks out the learning system of a machine learning algorithm into three main parts. A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative “evaluate and optimize” process, updating weights autonomously until a threshold of accuracy has been met. Industry newsletter The latest AI trends, brought to you by experts Get curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement. Thank you! You are subscribed. Your subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture1. Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers, which would be inclusive of the input and the output can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing (NLP), and speech recognition. See the blog post “AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?” for a closer look at how the different concepts relate. Mixture of Experts | 6 June, episode 58 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch the latest podcast episodes Machine learning methods Machine learning models fall into three primary categories. Supervised learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, Naïve Bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. Unsupervised learning’s ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It’s also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it’s too costly to label enough data. For a deep dive into the differences between these approaches, check out \"Supervised vs. Unsupervised Learning: What's the Difference?\" Reinforcement learning Reinforcement learning is a machine learning model that is similar to supervised learning, but the algorithm isn’t trained using sample data. This model learns as it goes by using trial and error. A sequence of successful outcomes will be reinforced to develop the best recommendation or policy for a given problem. The IBM Watson® system that won the Jeopardy! challenge in 2011 is a good example. The system used reinforcement learning to learn when to attempt an answer (or question, as it were), which square to select on the board, and how much to wager, especially on daily doubles. Common machine learning algorithms A number of machine learning algorithms are commonly used. These include: Neural networksLinear regressionLogistic regressionClusteringDecision treesRandom forests Neural networks Neural networks simulate the way the human brain works, with a huge number of linked processing nodes. Neural networks are good at recognizing patterns and play an important role in applications including natural language translation, image recognition, speech recognition, and image creation. Linear regression This algorithm is used to predict numerical values, based on a linear relationship between different values. For example, the technique could be used to predict house prices based on historical data for the area. Logistic regression This supervised learning algorithm makes predictions for categorical response variables, such as “yes/no” answers to questions. It can be used for applications such as classifying spam and quality control on a production line. Clustering Using unsupervised learning, clustering algorithms can identify patterns in data so that it can be grouped. Computers can help data scientists by identifying differences between data items that humans have overlooked. Decision trees Decision trees can be used for both predicting numerical values (regression) and classifying data into categories. Decision trees use a branching sequence of linked decisions that can be represented with a tree diagram. One of the advantages of decision trees is that they are easy to validate and audit, unlike the black box of the neural network. Random forests In a random forest, the machine learning algorithm predicts a value or category by combining the results from a number of decision trees. Advantages and disadvantages of machine learning algorithms Depending on your budget, need for speed and precision required, each algorithm type supervised, unsupervised, semi-supervised, or reinforcement has its own advantages and disadvantages. For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors. Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms, which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Real-world machine learning use cases Here are just a few examples of machine learning you might encounter every day: Generative AI: Generative AI, or gen AI, is machine learning that can create original content—text, images, video, software code—in response to a user’s prompt or request. Gen AI relies on deep learning models that identify and encode the patterns and relationships in huge amounts of data, and then use that information to understand users’ requests and create new content. ChatGPT and Claude.ai are examples of generative AI apps. AI agents and agentic AI: An AI agent is an autonomous AI program—it can perform tasks and accomplish goals on behalf of a user or another system without human intervention, by designing its own workflow and using available tools (other applications or services). Agentic AI is a system of multiple AI agents, the efforts of which are coordinated, or orchestrated, to accomplish a more complex task or a greater goal than any single agent in the system could accomplish. Explore our 2025 guide to AI agents Speech recognition: Also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, speech recognition uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search e.g. Siri or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites; messaging bots, using Slack and Facebook Messenger; and tasks usually done by virtual assistants and voice assistants. Computer vision: This AI technology enables computers to derive meaningful information from digital images, videos, and other visual inputs, and then take the appropriate action. Powered by convolutional neural networks, computer vision has applications in photo tagging on social media, radiology imaging in healthcare, and self-driving cars in the automotive industry. Recommendation engines: Using past consumption behavior data, AI algorithms can help to discover data trends that can be used to develop more effective cross-selling strategies. Recommendation engines are used by online retailers to make relevant product recommendations to customers during the checkout process. Robotic process automation (RPA): Also known as software robotics, RPA uses intelligent automation technologies to perform repetitive manual tasks. Automated stock trading: Designed to optimize stock portfolios, AI-driven high-frequency trading platforms make thousands or even millions of trades per day without human intervention. Fraud detection: Banks and other financial institutions can use machine learning to spot suspicious transactions. Supervised learning can train a model using information about known fraudulent transactions. Anomaly detection can identify transactions that look atypical and deserve further investigation. Challenges of machine learning As machine learning technology has developed, it has certainly made our lives easier. However, implementing machine learning in businesses has also raised a number of ethical concerns about AI technologies. Some of these include: Technological singularity While this topic garners a lot of public attention, many researchers are not concerned with the idea of AI surpassing human intelligence in the near future. Technological singularity is also referred to as strong AI or superintelligence. Philosopher Nick Bostrum defines superintelligence as “any intellect that vastly outperforms the best human brains in practically every field, including scientific creativity, general wisdom, and social skills.” Despite the fact that superintelligence is not imminent in society, the idea of it raises some interesting questions as we consider the use of autonomous systems, like self-driving cars. It’s unrealistic to think that a driverless car would never have an accident, but who is responsible and liable under those circumstances? Should we still develop autonomous vehicles, or do we limit this technology to semi-autonomous vehicles which help people drive safely? The jury is still out on this, but these are the types of ethical debates that are occurring as new, innovative AI technology develops. AI impact on jobs While a lot of public perception of artificial intelligence centers around job losses, this concern should probably be reframed. With every disruptive, new technology, we see that the market demand for specific job roles shifts. For example, when we look at the automotive industry, many manufacturers, like GM, are shifting to focus on electric vehicle production to align with green initiatives. The energy industry isn’t going away, but the source of energy is shifting from a fuel economy to an electric one. In a similar way, artificial intelligence will shift the demand for jobs to other areas. There will need to be individuals to help manage AI systems. There will still need to be people to address more complex problems within the industries that are most likely to be affected by job demand shifts, such as customer service. The biggest challenge with artificial intelligence and its effect on the job market will be helping people to transition to new roles that are in demand. Privacy Privacy tends to be discussed in the context of data privacy, data protection, and data security. These concerns have allowed policymakers to make more strides in recent years. For example, in 2016, GDPR legislation was created to protect the personal data of people in the European Union and European Economic Area, giving individuals more control of their data. In the United States, individual states are developing policies, such as the California Consumer Privacy Act (CCPA), which was introduced in 2018 and requires businesses to inform consumers about the collection of their data. Legislation such as this has forced companies to rethink how they store and use personally identifiable information (PII). As a result, investments in security have become an increasing priority for businesses as they seek to eliminate any vulnerabilities and opportunities for surveillance, hacking, and cyberattacks. Bias and discrimination Instances of bias and discrimination across a number of machine learning systems have raised many ethical questions regarding the use of artificial intelligence. How can we safeguard against bias and discrimination when the training data itself may be generated by biased human processes? While companies typically have good intentions for their automation efforts, Reuters2 highlights some of the unforeseen consequences of incorporating AI into hiring practices. In their effort to automate and simplify a process, Amazon unintentionally discriminated against job candidates by gender for technical roles, and the company ultimately had to scrap the project. Harvard Business Review3 has raised other pointed questions about the use of AI in hiring practices, such as what data you should be able to use when evaluating a candidate for a role. Bias and discrimination aren’t limited to the human resources function either; they can be found in a number of applications from facial recognition software to social media algorithms. As businesses become more aware of the risks with AI, they’ve also become more active in this discussion around AI ethics and values. Accountability Since there isn’t significant legislation to regulate AI practices, there is no real enforcement mechanism to ensure that ethical AI is practiced. The current incentives for companies to be ethical are the negative repercussions of an unethical AI system on the bottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration between ethicists and researchers to govern the construction and distribution of AI models within society. However, at the moment, these only serve to guide. Some research4 shows that the combination of distributed responsibility and a lack of foresight into potential consequences aren’t conducive to preventing harm to society. How to choose the right AI platform for machine learning Selecting a platform can be a challenging process, as the wrong system can drive up costs, or limit the use of other valuable tools or technologies. When reviewing multiple vendors to select an AI platform, there is often a tendency to think that more features = a better system. Maybe so, but reviewers should start by thinking through what the AI platform will be doing for their organization. What machine learning capabilities need to be delivered and what features are important to accomplish them? One missing feature might doom the usefulness of an entire system. Here are some features to consider. MLOps capabilities. Does the system have: a unified interface for ease of management? automated machine learning tools for faster model creation with low-code and no-code functionality?decision optimization to streamline the selection and deployment of optimization models?visual modeling to combine visual data science with open-source libraries and notebook-based interfaces on a unified data and AI studio?automated development for beginners to get started quickly and more advanced data scientists to experiment?synthetic data generator as an alternative or supplement to real-world data when real-world data is not readily available? Generative AI capabilities. Does the system have: a content generator that can generate text, images and other content based on the data it was trained on?automated classification to read and classify written input, such as evaluating and sorting customer complaints or reviewing customer feedback sentiment?a summary generator that can transform dense text into a high-quality summary, capture key points from financial reports, and generate meeting transcriptions?a data extraction capability to sort through complex details and quickly pull the necessary information from large documents? Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report",
  "What is machine learning? Machine learning (ML) is a branch of artificial intelligence (AI) focused on enabling computers and machines to imitate the way that humans learn, to perform tasks autonomously, and to improve their performance and accuracy through experience and exposure to more data. UC Berkeley breaks out the learning system of a machine learning algorithm into three main parts. A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data. An Error Function: An error function evaluates the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model. A Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this iterative “evaluate and optimize” process, updating weights autonomously until a threshold of accuracy has been met. Industry newsletter The latest AI trends, brought to you by experts Get curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement. Thank you! You are subscribed. Your subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information. Machine learning versus deep learning versus neural networks Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture1. Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers, which would be inclusive of the input and the output can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing (NLP), and speech recognition. See the blog post “AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?” for a closer look at how the different concepts relate. Mixture of Experts | 6 June, episode 58 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch the latest podcast episodes Machine learning methods Machine learning models fall into three primary categories. Supervised learning Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, Naïve Bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised learning Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. Unsupervised learning’s ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It’s also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it’s too costly to label enough data. For a deep dive into the differences between these approaches, check out \"Supervised vs. Unsupervised Learning: What's the Difference?\" Reinforcement learning Reinforcement learning is a machine learning model that is similar to supervised learning, but the algorithm isn’t trained using sample data. This model learns as it goes by using trial and error. A sequence of successful outcomes will be reinforced to develop the best recommendation or policy for a given problem. The IBM Watson® system that won the Jeopardy! challenge in 2011 is a good example. The system used reinforcement learning to learn when to attempt an answer (or question, as it were), which square to select on the board, and how much to wager, especially on daily doubles. Common machine learning algorithms A number of machine learning algorithms are commonly used. These include: Neural networksLinear regressionLogistic regressionClusteringDecision treesRandom forests Neural networks Neural networks simulate the way the human brain works, with a huge number of linked processing nodes. Neural networks are good at recognizing patterns and play an important role in applications including natural language translation, image recognition, speech recognition, and image creation. Linear regression This algorithm is used to predict numerical values, based on a linear relationship between different values. For example, the technique could be used to predict house prices based on historical data for the area. Logistic regression This supervised learning algorithm makes predictions for categorical response variables, such as “yes/no” answers to questions. It can be used for applications such as classifying spam and quality control on a production line. Clustering Using unsupervised learning, clustering algorithms can identify patterns in data so that it can be grouped. Computers can help data scientists by identifying differences between data items that humans have overlooked. Decision trees Decision trees can be used for both predicting numerical values (regression) and classifying data into categories. Decision trees use a branching sequence of linked decisions that can be represented with a tree diagram. One of the advantages of decision trees is that they are easy to validate and audit, unlike the black box of the neural network. Random forests In a random forest, the machine learning algorithm predicts a value or category by combining the results from a number of decision trees. Advantages and disadvantages of machine learning algorithms Depending on your budget, need for speed and precision required, each algorithm type supervised, unsupervised, semi-supervised, or reinforcement has its own advantages and disadvantages. For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors. Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms, which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Real-world machine learning use cases Here are just a few examples of machine learning you might encounter every day: Generative AI: Generative AI, or gen AI, is machine learning that can create original content—text, images, video, software code—in response to a user’s prompt or request. Gen AI relies on deep learning models that identify and encode the patterns and relationships in huge amounts of data, and then use that information to understand users’ requests and create new content. ChatGPT and Claude.ai are examples of generative AI apps. AI agents and agentic AI: An AI agent is an autonomous AI program—it can perform tasks and accomplish goals on behalf of a user or another system without human intervention, by designing its own workflow and using available tools (other applications or services). Agentic AI is a system of multiple AI agents, the efforts of which are coordinated, or orchestrated, to accomplish a more complex task or a greater goal than any single agent in the system could accomplish. Explore our 2025 guide to AI agents Speech recognition: Also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, speech recognition uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search e.g. Siri or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites; messaging bots, using Slack and Facebook Messenger; and tasks usually done by virtual assistants and voice assistants. Computer vision: This AI technology enables computers to derive meaningful information from digital images, videos, and other visual inputs, and then take the appropriate action. Powered by convolutional neural networks, computer vision has applications in photo tagging on social media, radiology imaging in healthcare, and self-driving cars in the automotive industry. Recommendation engines: Using past consumption behavior data, AI algorithms can help to discover data trends that can be used to develop more effective cross-selling strategies. Recommendation engines are used by online retailers to make relevant product recommendations to customers during the checkout process. Robotic process automation (RPA): Also known as software robotics, RPA uses intelligent automation technologies to perform repetitive manual tasks. Automated stock trading: Designed to optimize stock portfolios, AI-driven high-frequency trading platforms make thousands or even millions of trades per day without human intervention. Fraud detection: Banks and other financial institutions can use machine learning to spot suspicious transactions. Supervised learning can train a model using information about known fraudulent transactions. Anomaly detection can identify transactions that look atypical and deserve further investigation. Challenges of machine learning As machine learning technology has developed, it has certainly made our lives easier. However, implementing machine learning in businesses has also raised a number of ethical concerns about AI technologies. Some of these include: Technological singularity While this topic garners a lot of public attention, many researchers are not concerned with the idea of AI surpassing human intelligence in the near future. Technological singularity is also referred to as strong AI or superintelligence. Philosopher Nick Bostrum defines superintelligence as “any intellect that vastly outperforms the best human brains in practically every field, including scientific creativity, general wisdom, and social skills.” Despite the fact that superintelligence is not imminent in society, the idea of it raises some interesting questions as we consider the use of autonomous systems, like self-driving cars. It’s unrealistic to think that a driverless car would never have an accident, but who is responsible and liable under those circumstances? Should we still develop autonomous vehicles, or do we limit this technology to semi-autonomous vehicles which help people drive safely? The jury is still out on this, but these are the types of ethical debates that are occurring as new, innovative AI technology develops. AI impact on jobs While a lot of public perception of artificial intelligence centers around job losses, this concern should probably be reframed. With every disruptive, new technology, we see that the market demand for specific job roles shifts. For example, when we look at the automotive industry, many manufacturers, like GM, are shifting to focus on electric vehicle production to align with green initiatives. The energy industry isn’t going away, but the source of energy is shifting from a fuel economy to an electric one. In a similar way, artificial intelligence will shift the demand for jobs to other areas. There will need to be individuals to help manage AI systems. There will still need to be people to address more complex problems within the industries that are most likely to be affected by job demand shifts, such as customer service. The biggest challenge with artificial intelligence and its effect on the job market will be helping people to transition to new roles that are in demand. Privacy Privacy tends to be discussed in the context of data privacy, data protection, and data security. These concerns have allowed policymakers to make more strides in recent years. For example, in 2016, GDPR legislation was created to protect the personal data of people in the European Union and European Economic Area, giving individuals more control of their data. In the United States, individual states are developing policies, such as the California Consumer Privacy Act (CCPA), which was introduced in 2018 and requires businesses to inform consumers about the collection of their data. Legislation such as this has forced companies to rethink how they store and use personally identifiable information (PII). As a result, investments in security have become an increasing priority for businesses as they seek to eliminate any vulnerabilities and opportunities for surveillance, hacking, and cyberattacks. Bias and discrimination Instances of bias and discrimination across a number of machine learning systems have raised many ethical questions regarding the use of artificial intelligence. How can we safeguard against bias and discrimination when the training data itself may be generated by biased human processes? While companies typically have good intentions for their automation efforts, Reuters2 highlights some of the unforeseen consequences of incorporating AI into hiring practices. In their effort to automate and simplify a process, Amazon unintentionally discriminated against job candidates by gender for technical roles, and the company ultimately had to scrap the project. Harvard Business Review3 has raised other pointed questions about the use of AI in hiring practices, such as what data you should be able to use when evaluating a candidate for a role. Bias and discrimination aren’t limited to the human resources function either; they can be found in a number of applications from facial recognition software to social media algorithms. As businesses become more aware of the risks with AI, they’ve also become more active in this discussion around AI ethics and values. Accountability Since there isn’t significant legislation to regulate AI practices, there is no real enforcement mechanism to ensure that ethical AI is practiced. The current incentives for companies to be ethical are the negative repercussions of an unethical AI system on the bottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration between ethicists and researchers to govern the construction and distribution of AI models within society. However, at the moment, these only serve to guide. Some research4 shows that the combination of distributed responsibility and a lack of foresight into potential consequences aren’t conducive to preventing harm to society. How to choose the right AI platform for machine learning Selecting a platform can be a challenging process, as the wrong system can drive up costs, or limit the use of other valuable tools or technologies. When reviewing multiple vendors to select an AI platform, there is often a tendency to think that more features = a better system. Maybe so, but reviewers should start by thinking through what the AI platform will be doing for their organization. What machine learning capabilities need to be delivered and what features are important to accomplish them? One missing feature might doom the usefulness of an entire system. Here are some features to consider. MLOps capabilities. Does the system have: a unified interface for ease of management? automated machine learning tools for faster model creation with low-code and no-code functionality?decision optimization to streamline the selection and deployment of optimization models?visual modeling to combine visual data science with open-source libraries and notebook-based interfaces on a unified data and AI studio?automated development for beginners to get started quickly and more advanced data scientists to experiment?synthetic data generator as an alternative or supplement to real-world data when real-world data is not readily available? Generative AI capabilities. Does the system have: a content generator that can generate text, images and other content based on the data it was trained on?automated classification to read and classify written input, such as evaluating and sorting customer complaints or reviewing customer feedback sentiment?a summary generator that can transform dense text into a high-quality summary, capture key points from financial reports, and generate meeting transcriptions?a data extraction capability to sort through complex details and quickly pull the necessary information from large documents? Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Training Level up your ML expertise Learn fundamental concepts and build your skills with hands-on labs, courses, guided projects, trials and more. Explore ML courses Ebook Unlock the power of generative AI + ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide Put AI to work: Driving ROI with gen AI Want to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions. Read the guide Ebook How to choose the right foundation model Learn how to select the most suitable AI foundation model for your use case. Read the ebook AI models Explore IBM Granite IBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Guide How to thrive in this new era of AI with trust and confidence Dive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Report AI in Action Report We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Related solutions IBM watsonx.ai Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data. Discover watsonx.ai Artificial intelligence solutions Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions AI consulting and services Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value. Explore AI services Take the next step Get one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs. Explore watsonx.ai Book a live demo",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Training Level up your ML expertise Learn fundamental concepts and build your skills with hands-on labs, courses, guided projects, trials and more. Explore ML courses Ebook Unlock the power of generative AI + ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide Put AI to work: Driving ROI with gen AI Want to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions. Read the guide Ebook How to choose the right foundation model Learn how to select the most suitable AI foundation model for your use case. Read the ebook AI models Explore IBM Granite IBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Guide How to thrive in this new era of AI with trust and confidence Dive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Report AI in Action Report We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Related solutions IBM watsonx.ai Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data. Discover watsonx.ai Artificial intelligence solutions Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions AI consulting and services Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value. Explore AI services Take the next step Get one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs. Explore watsonx.ai Book a live demo",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Training Level up your ML expertise Learn fundamental concepts and build your skills with hands-on labs, courses, guided projects, trials and more. Explore ML courses Ebook Unlock the power of generative AI + ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide Put AI to work: Driving ROI with gen AI Want to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions. Read the guide Ebook How to choose the right foundation model Learn how to select the most suitable AI foundation model for your use case. Read the ebook AI models Explore IBM Granite IBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Guide How to thrive in this new era of AI with trust and confidence Dive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Report AI in Action Report We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Training Level up your ML expertise Learn fundamental concepts and build your skills with hands-on labs, courses, guided projects, trials and more. Explore ML courses Ebook Unlock the power of generative AI + ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide Put AI to work: Driving ROI with gen AI Want to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions. Read the guide Ebook How to choose the right foundation model Learn how to select the most suitable AI foundation model for your use case. Read the ebook AI models Explore IBM Granite IBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Guide How to thrive in this new era of AI with trust and confidence Dive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Report AI in Action Report We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report",
  "But in 2024, most AI researchers, practitioners and most AI-related headlines are focused on breakthroughs in generative AI (gen AI), a technology that can create original text, images, video and other content. To fully understand generative AI, it’s important to first understand the technologies on which generative AI tools are built: machine learning (ML) and deep learning.",
  "Authors Cole Stryker Editorial Lead, AI Models Eda Kavlakoglu Program Manager What is AI? Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy. Applications and devices equipped with AI can see and identify objects. They can understand and respond to human language. They can learn from new information and experience. They can make detailed recommendations to users and experts. They can act independently, replacing the need for human intelligence or intervention (a classic example being a self-driving car). But in 2024, most AI researchers, practitioners and most AI-related headlines are focused on breakthroughs in generative AI (gen AI), a technology that can create original text, images, video and other content. To fully understand generative AI, it’s important to first understand the technologies on which generative AI tools are built: machine learning (ML) and deep learning. Industry newsletter The latest tech news, backed by expert insights Stay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter. See the IBM Privacy Statement. Thank you! You are subscribed. Your subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information. Machine learning A simple way to think about AI is as a series of nested or derivative concepts that have emerged over more than 70 years: Directly underneath AI, we have machine learning, which involves creating models by training an algorithm to make predictions or decisions based on data. It encompasses a broad range of techniques that enable computers to learn from and make inferences based on data without being explicitly programmed for specific tasks. There are many types of machine learning techniques or algorithms, including linear regression, logistic regression, decision trees, random forest, support vector machines (SVMs), k-nearest neighbor (KNN), clustering and more. Each of these approaches is suited to different kinds of problems and data. But one of the most popular types of machine learning algorithm is called a neural network (or artificial neural network). Neural networks are modeled after the human brain's structure and function. A neural network consists of interconnected layers of nodes (analogous to neurons) that work together to process and analyze complex data. Neural networks are well suited to tasks that involve identifying complex patterns and relationships in large amounts of data. The simplest form of machine learning is called supervised learning, which involves the use of labeled data sets to train algorithms to classify data or predict outcomes accurately. In supervised learning, humans pair each training example with an output label. The goal is for the model to learn the mapping between inputs and outputs in the training data, so it can predict the labels of new, unseen data. Deep learning Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, that more closely simulate the complex decision-making power of the human brain. Deep neural networks include an input layer, at least three but usually hundreds of hidden layers, and an output layer, unlike neural networks used in classic machine learning models, which usually have only one or two hidden layers. These multiple layers enable unsupervised learning: they can automate the extraction of features from large, unlabeled and unstructured data sets, and make their own predictions about what the data represents. Because deep learning doesn’t require human intervention, it enables machine learning at a tremendous scale. It is well suited to natural language processing (NLP), computer vision, and other tasks that involve the fast, accurate identification complex patterns and relationships in large amounts of data. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today. Deep learning also enables: Semi-supervised learning, which combines supervised and unsupervised learning by using both labeled and unlabeled data to train AI models for classification and regression tasks. Self-supervised learning, which generates implicit labels from unstructured data, rather than relying on labeled data sets for supervisory signals. Reinforcement learning, which learns by trial-and-error and reward functions rather than by extracting information from hidden patterns. Transfer learning, in which knowledge gained through one task or data set is used to improve model performance on another related task or different data set. Generative AI Generative AI, sometimes called \"gen AI\", refers to deep learning models that can create complex original content such as long-form text, high-quality images, realistic video or audio and more in response to a user’s prompt or request. At a high level, generative models encode a simplified representation of their training data, and then draw from that representation to create new work that’s similar, but not identical, to the original data. Generative models have been used for years in statistics to analyze numerical data. But over the last decade, they evolved to analyze and generate more complex data types. This evolution coincided with the emergence of three sophisticated deep learning model types: Variational autoencoders or VAEs, which were introduced in 2013, and enabled models that could generate multiple variations of content in response to a prompt or instruction. Diffusion models, first seen in 2014, which add \"noise\" to images until they are unrecognizable, and then remove the noise to generate original images in response to prompts. Transformers (also called transformer models), which are trained on sequenced data to generate extended sequences of content (such as words in sentences, shapes in an image, frames of a video or commands in software code). Transformers are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard and Midjourney. Mixture of Experts | 6 June, episode 58 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch the latest podcast episodes How generative AI works In general, generative AI operates in three phases: Training, to create a foundation model.Tuning, to adapt the model to a specific application.Generation, evaluation and more tuning, to improve accuracy. Training Generative AI begins with a \"foundation model\"; a deep learning model that serves as the basis for multiple different types of generative AI applications. The most common foundation models today are large language models (LLMs), created for text generation applications. But there are also foundation models for image, video, sound or music generation, and multimodal foundation models that support several kinds of content. To create a foundation model, practitioners train a deep learning algorithm on huge volumes of relevant raw, unstructured, unlabeled data, such as terabytes or petabytes of data text or images or video from the internet. The training yields a neural network of billions of parameters encoded representations of the entities, patterns and relationships in the data that can generate content autonomously in response to prompts. This is the foundation model. This training process is compute-intensive, time-consuming and expensive. It requires thousands of clustered graphics processing units (GPUs) and weeks of processing, all of which typically costs millions of dollars. Open source foundation model projects, such as Meta's Llama-2, enable gen AI developers to avoid this step and its costs. Tuning Next, the model must be tuned to a specific content generation task. This can be done in various ways, including: Fine-tuning, which involves feeding the model application-specific labeled data, questions or prompts the application is likely to receive, and corresponding correct answers in the wanted format. Reinforcement learning with human feedback (RLHF), in which human users evaluate the accuracy or relevance of model outputs so that the model can improve itself. This can be as simple as having people type or talk back corrections to a chatbot or virtual assistant. Generation, evaluation and more tuning Developers and users regularly assess the outputs of their generative AI apps, and further tune the model even as often as once a week for greater accuracy or relevance. In contrast, the foundation model itself is updated much less frequently, perhaps every year or 18 months. Another option for improving a gen AI app's performance is retrieval augmented generation (RAG), a technique for extending the foundation model to use relevant sources outside of the training data to refine the parameters for greater accuracy or relevance. AI agents and agentic AI An AI agent is an autonomous AI program, it can perform tasks and accomplish goals on behalf of a user or another system without human intervention, by designing its own workflow and using available tools (other applications or services). Agentic AI is a system of multiple AI agents, the efforts of which are coordinated, or orchestrated, to accomplish a more complex task or a greater goal than any single agent in the system could accomplish. Unlike chatbots and other AI models which operate within predefined constraints and require human intervention, AI agents and agentic AI exhibit autonomy, goal-driven behavior and adaptability to changing circumstances. The terms “agent” and “agentic” refer to these models’ agency, or their capacity to act independently and purposefully. One way to think of agents is as a natural next step after generative AI. Gen AI models focus on creating content based on learned patterns; agents use that content to interact with each other and other tools to make decisions, solve problems and complete tasks. For example, a gen AI app might be able to tell you the best time to climb Mt. Everest given your work schedule, but an agent can tell you this, and then use an online travel service to book you the best flight and reserve a room in the most convenient hotel in Nepal. Explore our 2025 guide to AI agents Benefits of AI AI offers numerous benefits across various industries and applications. Some of the most commonly cited benefits include: Automation of repetitive tasks.More and faster insight from data. Enhanced decision-making. Fewer human errors.24x7 availability.Reduced physical risks. Automation of repetitive tasks AI can automate routine, repetitive and often tedious tasks including digital tasks such as data collection, entering and preprocessing, and physical tasks such as warehouse stock-picking and manufacturing processes. This automation frees to work on higher value, more creative work. Enhanced decision-making Whether used for decision support or for fully automated decision-making, AI enables faster, more accurate predictions and reliable, data-driven decisions. Combined with automation, AI enables businesses to act on opportunities and respond to crises as they emerge, in real time and without human intervention. Fewer human errors AI can reduce human errors in various ways, from guiding people through the proper steps of a process, to flagging potential errors before they occur, and fully automating processes without human intervention. This is especially important in industries such as healthcare where, for example, AI-guided surgical robotics enable consistent precision. Machine learning algorithms can continually improve their accuracy and further reduce errors as they're exposed to more data and \"learn\" from experience. Round-the-clock availability and consistency AI is always on, available around the clock, and delivers consistent performance every time. Tools such as AI chatbots or virtual assistants can lighten staffing demands for customer service or support. In other applications such as materials processing or production lines, AI can help maintain consistent work quality and output levels when used to complete repetitive or tedious tasks. Reduced physical risk By automating dangerous work such as animal control, handling explosives, performing tasks in deep ocean water, high altitudes or in outer space, AI can eliminate the need to put human workers at risk of injury or worse. While they have yet to be perfected, self-driving cars and other vehicles offer the potential to reduce the risk of injury to passengers. AI use cases The real-world applications of AI are many. Here is just a small sampling of use cases across various industries to illustrate its potential: Customer experience, service and support Companies can implement AI-powered chatbots and virtual assistants to handle customer inquiries, support tickets and more. These tools use natural language processing (NLP) and generative AI capabilities to understand and respond to customer questions about order status, product details and return policies. Chatbots and virtual assistants enable always-on support, provide faster answers to frequently asked questions (FAQs), free human agents to focus on higher-level tasks, and give customers faster, more consistent service. Fraud detection Machine learning and deep learning algorithms can analyze transaction patterns and flag anomalies, such as unusual spending or login locations, that indicate fraudulent transactions. This enables organizations to respond more quickly to potential fraud and limit its impact, giving themselves and customers greater peace of mind. Personalized marketing Retailers, banks and other customer-facing companies can use AI to create personalized customer experiences and marketing campaigns that delight customers, improve sales and prevent churn. Based on data from customer purchase history and behaviors, deep learning algorithms can recommend products and services customers are likely to want, and even generate personalized copy and special offers for individual customers in real time. Human resources and recruitment AI-driven recruitment platforms can streamline hiring by screening resumes, matching candidates with job descriptions, and even conducting preliminary interviews using video analysis. These and other tools can dramatically reduce the mountain of administrative paperwork associated with fielding a large volume of candidates. It can also reduce response times and time-to-hire, improving the experience for candidates whether they get the job or not. Application development and modernization Generative AI code generation tools and automation tools can streamline repetitive coding tasks associated with application development, and accelerate the migration and modernization (reformatting and replatorming) of legacy applications at scale. These tools can speed up tasks, help ensure code consistency and reduce errors. Predictive maintenance Machine learning models can analyze data from sensors, Internet of Things (IoT) devices and operational technology (OT) to forecast when maintenance will be required and predict equipment failures before they occur. AI-powered preventive maintenance helps prevent downtime and enables you to stay ahead of supply chain issues before they affect the bottom line. AI challenges and risks Organizations are scrambling to take advantage of the latest AI technologies and capitalize on AI's many benefits. This rapid adoption is necessary, but adopting and maintaining AI workflows comes with challenges and risks. Data risks AI systems rely on data sets that might be vulnerable to data poisoning, data tampering, data bias or cyberattacks that can lead to data breaches. Organizations can mitigate these risks by protecting data integrity and implementing security and availability throughout the entire AI lifecycle, from development to training and deployment and postdeployment. Model risks Threat actors can target AI models for theft, reverse engineering or unauthorized manipulation. Attackers might compromise a model’s integrity by tampering with its architecture, weights or parameters; the core components that determine a model’s behavior, accuracy and performance. Operational risks Like all technologies, models are susceptible to operational risks such as model drift, bias and breakdowns in the governance structure. Left unaddressed, these risks can lead to system failures and cybersecurity vulnerabilities that threat actors can use. Ethics and legal risks If organizations don’t prioritize safety and ethics when developing and deploying AI systems, they risk committing privacy violations and producing biased outcomes. For example, biased training data used for hiring decisions might reinforce gender or racial stereotypes and create AI models that favor certain demographic groups over others. AI ethics and governance AI ethics is a multidisciplinary field that studies how to optimize AI's beneficial impact while reducing risks and adverse outcomes. Principles of AI ethics are applied through a system of AI governance consisted of guardrails that help ensure that AI tools and systems remain safe and ethical. AI governance encompasses oversight mechanisms that address risks. An ethical approach to AI governance requires the involvement of a wide range of stakeholders, including developers, users, policymakers and ethicists, helping to ensure that AI-related systems are developed and used to align with society's values. Here are common values associated with AI ethics and responsible AI: Explainability and interpretability As AI becomes more advanced, humans are challenged to comprehend and retrace how the algorithm came to a result. Explainable AI is a set of processes and methods that enables human users to interpret, comprehend and trust the results and output created by algorithms. Fairness and inclusion Although machine learning, by its very nature, is a form of statistical discrimination, the discrimination becomes objectionable when it places privileged groups at systematic advantage and certain unprivileged groups at systematic disadvantage, potentially causing varied harms. To encourage fairness, practitioners can try to minimize algorithmic bias across data collection and model design, and to build more diverse and inclusive teams. Robustness and security Robust AI effectively handles exceptional conditions, such as abnormalities in input or malicious attacks, without causing unintentional harm. It is also built to withstand intentional and unintentional interference by protecting against exposed vulnerabilities. Accountability and transparency Organizations should implement clear responsibilities and governance structures for the development, deployment and outcomes of AI systems. In addition, users should be able to see how an AI service works, evaluate its functionality, and comprehend its strengths and limitations. Increased transparency provides information for AI consumers to better understand how the AI model or service was created. Privacy and compliance Many regulatory frameworks, including GDPR, mandate that organizations abide by certain privacy principles when processing personal information. It is crucial to be able to protect AI models that might contain personal information, control what data goes into the model in the first place, and to build adaptable systems that can adjust to changes in regulation and attitudes around AI ethics. Weak AI vs. Strong AI In order to contextualize the use of AI at various levels of complexity and sophistication, researchers have defined several types of AI that refer to its level of sophistication: Weak AI: Also known as “narrow AI,” defines AI systems designed to perform a specific task or a set of tasks. Examples might include “smart” voice assistant apps, such as Amazon’s Alexa, Apple’s Siri, a social media chatbot or the autonomous vehicles promised by Tesla. Strong AI: Also known as “artificial general intelligence” (AGI) or “general AI,” possess the ability to understand, learn and apply knowledge across a wide range of tasks at a level equal to or surpassing human intelligence. This level of AI is currently theoretical and no known AI systems approach this level of sophistication. Researchers argue that if AGI is even possible, it requires major increases in computing power. Despite recent advances in AI development, self-aware AI systems of science fiction remain firmly in that realm. History of AI The idea of \"a machine that thinks\" dates back to ancient Greece. But since the advent of electronic computing (and relative to some of the topics discussed in this article) important events and milestones in the evolution of AI include the following: 1950 Alan Turing publishes Computing Machinery and Intelligence. In this paper, Turing famous for breaking the German ENIGMA code during WWII and often referred to as the \"father of computer science\" asks the following question: \"Can machines think?\" From there, he offers a test, now famously known as the \"Turing Test,\" where a human interrogator would try to distinguish between a computer and human text response. While this test has undergone much scrutiny since it was published, it remains an important part of the history of AI, and an ongoing concept within philosophy as it uses ideas around linguistics. 1956 John McCarthy coins the term \"artificial intelligence\" at the first-ever AI conference at Dartmouth College. (McCarthy went on to invent the Lisp language.) Later that year, Allen Newell, J.C. Shaw and Herbert Simon create the Logic Theorist, the first-ever running AI computer program. 1967 Frank Rosenblatt builds the Mark 1 Perceptron, the first computer based on a neural network that \"learned\" through trial and error. Just a year later, Marvin Minsky and Seymour Papert publish a book titled Perceptrons, which becomes both the landmark work on neural networks and, at least for a while, an argument against future neural network research initiatives. 1980 Neural networks, which use a backpropagation algorithm to train itself, became widely used in AI applications. 1995 Stuart Russell and Peter Norvig publish Artificial Intelligence: A Modern Approach, which becomes one of the leading textbooks in the study of AI. In it, they delve into four potential goals or definitions of AI, which differentiates computer systems based on rationality and thinking versus acting. 1997 IBM's Deep Blue beats then world chess champion Garry Kasparov, in a chess match (and rematch). 2004 John McCarthy writes a paper, What Is Artificial Intelligence?, and proposes an often-cited definition of AI. By this time, the era of big data and cloud computing is underway, enabling organizations to manage ever-larger data estates, which will one day be used to train AI models. 2011 IBM Watson® beats champions Ken Jennings and Brad Rutter at Jeopardy! Also, around this time, data science begins to emerge as a popular discipline. 2015 Baidu's Minwa supercomputer uses a special deep neural network called a convolutional neural network to identify and categorize images with a higher rate of accuracy than the average human. 2016 DeepMind's AlphaGo program, powered by a deep neural network, beats Lee Sodol, the world champion Go player, in a five-game match. The victory is significant given the huge number of possible moves as the game progresses (over 14.5 trillion after just four moves). Later, Google purchased DeepMind for a reported USD 400 million. 2022 A rise in large language models or LLMs, such as OpenAI’s ChatGPT, creates an enormous change in performance of AI and its potential to drive enterprise value. With these new generative AI practices, deep-learning models can be pretrained on large amounts of data. 2024 The latest AI trends point to a continuing AI renaissance. Multimodal models that can take multiple types of data as input are providing richer, more robust experiences. These models bring together computer vision image recognition and NLP speech recognition capabilities. Smaller models are also making strides in an age of diminishing returns with massive models with large parameter counts. Ebook How to choose the right foundation model Learn how to choose the right approach in preparing datasets and employing foundation models. Read the ebook",
  "Authors Cole Stryker Editorial Lead, AI Models Eda Kavlakoglu Program Manager What is AI? Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy. Applications and devices equipped with AI can see and identify objects. They can understand and respond to human language. They can learn from new information and experience. They can make detailed recommendations to users and experts. They can act independently, replacing the need for human intelligence or intervention (a classic example being a self-driving car). But in 2024, most AI researchers, practitioners and most AI-related headlines are focused on breakthroughs in generative AI (gen AI), a technology that can create original text, images, video and other content. To fully understand generative AI, it’s important to first understand the technologies on which generative AI tools are built: machine learning (ML) and deep learning. Industry newsletter The latest tech news, backed by expert insights Stay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter. See the IBM Privacy Statement. Thank you! You are subscribed. Your subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information. Machine learning A simple way to think about AI is as a series of nested or derivative concepts that have emerged over more than 70 years: Directly underneath AI, we have machine learning, which involves creating models by training an algorithm to make predictions or decisions based on data. It encompasses a broad range of techniques that enable computers to learn from and make inferences based on data without being explicitly programmed for specific tasks. There are many types of machine learning techniques or algorithms, including linear regression, logistic regression, decision trees, random forest, support vector machines (SVMs), k-nearest neighbor (KNN), clustering and more. Each of these approaches is suited to different kinds of problems and data. But one of the most popular types of machine learning algorithm is called a neural network (or artificial neural network). Neural networks are modeled after the human brain's structure and function. A neural network consists of interconnected layers of nodes (analogous to neurons) that work together to process and analyze complex data. Neural networks are well suited to tasks that involve identifying complex patterns and relationships in large amounts of data. The simplest form of machine learning is called supervised learning, which involves the use of labeled data sets to train algorithms to classify data or predict outcomes accurately. In supervised learning, humans pair each training example with an output label. The goal is for the model to learn the mapping between inputs and outputs in the training data, so it can predict the labels of new, unseen data. Deep learning Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, that more closely simulate the complex decision-making power of the human brain. Deep neural networks include an input layer, at least three but usually hundreds of hidden layers, and an output layer, unlike neural networks used in classic machine learning models, which usually have only one or two hidden layers. These multiple layers enable unsupervised learning: they can automate the extraction of features from large, unlabeled and unstructured data sets, and make their own predictions about what the data represents. Because deep learning doesn’t require human intervention, it enables machine learning at a tremendous scale. It is well suited to natural language processing (NLP), computer vision, and other tasks that involve the fast, accurate identification complex patterns and relationships in large amounts of data. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today. Deep learning also enables: Semi-supervised learning, which combines supervised and unsupervised learning by using both labeled and unlabeled data to train AI models for classification and regression tasks. Self-supervised learning, which generates implicit labels from unstructured data, rather than relying on labeled data sets for supervisory signals. Reinforcement learning, which learns by trial-and-error and reward functions rather than by extracting information from hidden patterns. Transfer learning, in which knowledge gained through one task or data set is used to improve model performance on another related task or different data set. Generative AI Generative AI, sometimes called \"gen AI\", refers to deep learning models that can create complex original content such as long-form text, high-quality images, realistic video or audio and more in response to a user’s prompt or request. At a high level, generative models encode a simplified representation of their training data, and then draw from that representation to create new work that’s similar, but not identical, to the original data. Generative models have been used for years in statistics to analyze numerical data. But over the last decade, they evolved to analyze and generate more complex data types. This evolution coincided with the emergence of three sophisticated deep learning model types: Variational autoencoders or VAEs, which were introduced in 2013, and enabled models that could generate multiple variations of content in response to a prompt or instruction. Diffusion models, first seen in 2014, which add \"noise\" to images until they are unrecognizable, and then remove the noise to generate original images in response to prompts. Transformers (also called transformer models), which are trained on sequenced data to generate extended sequences of content (such as words in sentences, shapes in an image, frames of a video or commands in software code). Transformers are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard and Midjourney. Mixture of Experts | 6 June, episode 58 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch the latest podcast episodes How generative AI works In general, generative AI operates in three phases: Training, to create a foundation model.Tuning, to adapt the model to a specific application.Generation, evaluation and more tuning, to improve accuracy. Training Generative AI begins with a \"foundation model\"; a deep learning model that serves as the basis for multiple different types of generative AI applications. The most common foundation models today are large language models (LLMs), created for text generation applications. But there are also foundation models for image, video, sound or music generation, and multimodal foundation models that support several kinds of content. To create a foundation model, practitioners train a deep learning algorithm on huge volumes of relevant raw, unstructured, unlabeled data, such as terabytes or petabytes of data text or images or video from the internet. The training yields a neural network of billions of parameters encoded representations of the entities, patterns and relationships in the data that can generate content autonomously in response to prompts. This is the foundation model. This training process is compute-intensive, time-consuming and expensive. It requires thousands of clustered graphics processing units (GPUs) and weeks of processing, all of which typically costs millions of dollars. Open source foundation model projects, such as Meta's Llama-2, enable gen AI developers to avoid this step and its costs. Tuning Next, the model must be tuned to a specific content generation task. This can be done in various ways, including: Fine-tuning, which involves feeding the model application-specific labeled data, questions or prompts the application is likely to receive, and corresponding correct answers in the wanted format. Reinforcement learning with human feedback (RLHF), in which human users evaluate the accuracy or relevance of model outputs so that the model can improve itself. This can be as simple as having people type or talk back corrections to a chatbot or virtual assistant. Generation, evaluation and more tuning Developers and users regularly assess the outputs of their generative AI apps, and further tune the model even as often as once a week for greater accuracy or relevance. In contrast, the foundation model itself is updated much less frequently, perhaps every year or 18 months. Another option for improving a gen AI app's performance is retrieval augmented generation (RAG), a technique for extending the foundation model to use relevant sources outside of the training data to refine the parameters for greater accuracy or relevance. AI agents and agentic AI An AI agent is an autonomous AI program, it can perform tasks and accomplish goals on behalf of a user or another system without human intervention, by designing its own workflow and using available tools (other applications or services). Agentic AI is a system of multiple AI agents, the efforts of which are coordinated, or orchestrated, to accomplish a more complex task or a greater goal than any single agent in the system could accomplish. Unlike chatbots and other AI models which operate within predefined constraints and require human intervention, AI agents and agentic AI exhibit autonomy, goal-driven behavior and adaptability to changing circumstances. The terms “agent” and “agentic” refer to these models’ agency, or their capacity to act independently and purposefully. One way to think of agents is as a natural next step after generative AI. Gen AI models focus on creating content based on learned patterns; agents use that content to interact with each other and other tools to make decisions, solve problems and complete tasks. For example, a gen AI app might be able to tell you the best time to climb Mt. Everest given your work schedule, but an agent can tell you this, and then use an online travel service to book you the best flight and reserve a room in the most convenient hotel in Nepal. Explore our 2025 guide to AI agents Benefits of AI AI offers numerous benefits across various industries and applications. Some of the most commonly cited benefits include: Automation of repetitive tasks.More and faster insight from data. Enhanced decision-making. Fewer human errors.24x7 availability.Reduced physical risks. Automation of repetitive tasks AI can automate routine, repetitive and often tedious tasks including digital tasks such as data collection, entering and preprocessing, and physical tasks such as warehouse stock-picking and manufacturing processes. This automation frees to work on higher value, more creative work. Enhanced decision-making Whether used for decision support or for fully automated decision-making, AI enables faster, more accurate predictions and reliable, data-driven decisions. Combined with automation, AI enables businesses to act on opportunities and respond to crises as they emerge, in real time and without human intervention. Fewer human errors AI can reduce human errors in various ways, from guiding people through the proper steps of a process, to flagging potential errors before they occur, and fully automating processes without human intervention. This is especially important in industries such as healthcare where, for example, AI-guided surgical robotics enable consistent precision. Machine learning algorithms can continually improve their accuracy and further reduce errors as they're exposed to more data and \"learn\" from experience. Round-the-clock availability and consistency AI is always on, available around the clock, and delivers consistent performance every time. Tools such as AI chatbots or virtual assistants can lighten staffing demands for customer service or support. In other applications such as materials processing or production lines, AI can help maintain consistent work quality and output levels when used to complete repetitive or tedious tasks. Reduced physical risk By automating dangerous work such as animal control, handling explosives, performing tasks in deep ocean water, high altitudes or in outer space, AI can eliminate the need to put human workers at risk of injury or worse. While they have yet to be perfected, self-driving cars and other vehicles offer the potential to reduce the risk of injury to passengers. AI use cases The real-world applications of AI are many. Here is just a small sampling of use cases across various industries to illustrate its potential: Customer experience, service and support Companies can implement AI-powered chatbots and virtual assistants to handle customer inquiries, support tickets and more. These tools use natural language processing (NLP) and generative AI capabilities to understand and respond to customer questions about order status, product details and return policies. Chatbots and virtual assistants enable always-on support, provide faster answers to frequently asked questions (FAQs), free human agents to focus on higher-level tasks, and give customers faster, more consistent service. Fraud detection Machine learning and deep learning algorithms can analyze transaction patterns and flag anomalies, such as unusual spending or login locations, that indicate fraudulent transactions. This enables organizations to respond more quickly to potential fraud and limit its impact, giving themselves and customers greater peace of mind. Personalized marketing Retailers, banks and other customer-facing companies can use AI to create personalized customer experiences and marketing campaigns that delight customers, improve sales and prevent churn. Based on data from customer purchase history and behaviors, deep learning algorithms can recommend products and services customers are likely to want, and even generate personalized copy and special offers for individual customers in real time. Human resources and recruitment AI-driven recruitment platforms can streamline hiring by screening resumes, matching candidates with job descriptions, and even conducting preliminary interviews using video analysis. These and other tools can dramatically reduce the mountain of administrative paperwork associated with fielding a large volume of candidates. It can also reduce response times and time-to-hire, improving the experience for candidates whether they get the job or not. Application development and modernization Generative AI code generation tools and automation tools can streamline repetitive coding tasks associated with application development, and accelerate the migration and modernization (reformatting and replatorming) of legacy applications at scale. These tools can speed up tasks, help ensure code consistency and reduce errors. Predictive maintenance Machine learning models can analyze data from sensors, Internet of Things (IoT) devices and operational technology (OT) to forecast when maintenance will be required and predict equipment failures before they occur. AI-powered preventive maintenance helps prevent downtime and enables you to stay ahead of supply chain issues before they affect the bottom line. AI challenges and risks Organizations are scrambling to take advantage of the latest AI technologies and capitalize on AI's many benefits. This rapid adoption is necessary, but adopting and maintaining AI workflows comes with challenges and risks. Data risks AI systems rely on data sets that might be vulnerable to data poisoning, data tampering, data bias or cyberattacks that can lead to data breaches. Organizations can mitigate these risks by protecting data integrity and implementing security and availability throughout the entire AI lifecycle, from development to training and deployment and postdeployment. Model risks Threat actors can target AI models for theft, reverse engineering or unauthorized manipulation. Attackers might compromise a model’s integrity by tampering with its architecture, weights or parameters; the core components that determine a model’s behavior, accuracy and performance. Operational risks Like all technologies, models are susceptible to operational risks such as model drift, bias and breakdowns in the governance structure. Left unaddressed, these risks can lead to system failures and cybersecurity vulnerabilities that threat actors can use. Ethics and legal risks If organizations don’t prioritize safety and ethics when developing and deploying AI systems, they risk committing privacy violations and producing biased outcomes. For example, biased training data used for hiring decisions might reinforce gender or racial stereotypes and create AI models that favor certain demographic groups over others. AI ethics and governance AI ethics is a multidisciplinary field that studies how to optimize AI's beneficial impact while reducing risks and adverse outcomes. Principles of AI ethics are applied through a system of AI governance consisted of guardrails that help ensure that AI tools and systems remain safe and ethical. AI governance encompasses oversight mechanisms that address risks. An ethical approach to AI governance requires the involvement of a wide range of stakeholders, including developers, users, policymakers and ethicists, helping to ensure that AI-related systems are developed and used to align with society's values. Here are common values associated with AI ethics and responsible AI: Explainability and interpretability As AI becomes more advanced, humans are challenged to comprehend and retrace how the algorithm came to a result. Explainable AI is a set of processes and methods that enables human users to interpret, comprehend and trust the results and output created by algorithms. Fairness and inclusion Although machine learning, by its very nature, is a form of statistical discrimination, the discrimination becomes objectionable when it places privileged groups at systematic advantage and certain unprivileged groups at systematic disadvantage, potentially causing varied harms. To encourage fairness, practitioners can try to minimize algorithmic bias across data collection and model design, and to build more diverse and inclusive teams. Robustness and security Robust AI effectively handles exceptional conditions, such as abnormalities in input or malicious attacks, without causing unintentional harm. It is also built to withstand intentional and unintentional interference by protecting against exposed vulnerabilities. Accountability and transparency Organizations should implement clear responsibilities and governance structures for the development, deployment and outcomes of AI systems. In addition, users should be able to see how an AI service works, evaluate its functionality, and comprehend its strengths and limitations. Increased transparency provides information for AI consumers to better understand how the AI model or service was created. Privacy and compliance Many regulatory frameworks, including GDPR, mandate that organizations abide by certain privacy principles when processing personal information. It is crucial to be able to protect AI models that might contain personal information, control what data goes into the model in the first place, and to build adaptable systems that can adjust to changes in regulation and attitudes around AI ethics. Weak AI vs. Strong AI In order to contextualize the use of AI at various levels of complexity and sophistication, researchers have defined several types of AI that refer to its level of sophistication: Weak AI: Also known as “narrow AI,” defines AI systems designed to perform a specific task or a set of tasks. Examples might include “smart” voice assistant apps, such as Amazon’s Alexa, Apple’s Siri, a social media chatbot or the autonomous vehicles promised by Tesla. Strong AI: Also known as “artificial general intelligence” (AGI) or “general AI,” possess the ability to understand, learn and apply knowledge across a wide range of tasks at a level equal to or surpassing human intelligence. This level of AI is currently theoretical and no known AI systems approach this level of sophistication. Researchers argue that if AGI is even possible, it requires major increases in computing power. Despite recent advances in AI development, self-aware AI systems of science fiction remain firmly in that realm. History of AI The idea of \"a machine that thinks\" dates back to ancient Greece. But since the advent of electronic computing (and relative to some of the topics discussed in this article) important events and milestones in the evolution of AI include the following: 1950 Alan Turing publishes Computing Machinery and Intelligence. In this paper, Turing famous for breaking the German ENIGMA code during WWII and often referred to as the \"father of computer science\" asks the following question: \"Can machines think?\" From there, he offers a test, now famously known as the \"Turing Test,\" where a human interrogator would try to distinguish between a computer and human text response. While this test has undergone much scrutiny since it was published, it remains an important part of the history of AI, and an ongoing concept within philosophy as it uses ideas around linguistics. 1956 John McCarthy coins the term \"artificial intelligence\" at the first-ever AI conference at Dartmouth College. (McCarthy went on to invent the Lisp language.) Later that year, Allen Newell, J.C. Shaw and Herbert Simon create the Logic Theorist, the first-ever running AI computer program. 1967 Frank Rosenblatt builds the Mark 1 Perceptron, the first computer based on a neural network that \"learned\" through trial and error. Just a year later, Marvin Minsky and Seymour Papert publish a book titled Perceptrons, which becomes both the landmark work on neural networks and, at least for a while, an argument against future neural network research initiatives. 1980 Neural networks, which use a backpropagation algorithm to train itself, became widely used in AI applications. 1995 Stuart Russell and Peter Norvig publish Artificial Intelligence: A Modern Approach, which becomes one of the leading textbooks in the study of AI. In it, they delve into four potential goals or definitions of AI, which differentiates computer systems based on rationality and thinking versus acting. 1997 IBM's Deep Blue beats then world chess champion Garry Kasparov, in a chess match (and rematch). 2004 John McCarthy writes a paper, What Is Artificial Intelligence?, and proposes an often-cited definition of AI. By this time, the era of big data and cloud computing is underway, enabling organizations to manage ever-larger data estates, which will one day be used to train AI models. 2011 IBM Watson® beats champions Ken Jennings and Brad Rutter at Jeopardy! Also, around this time, data science begins to emerge as a popular discipline. 2015 Baidu's Minwa supercomputer uses a special deep neural network called a convolutional neural network to identify and categorize images with a higher rate of accuracy than the average human. 2016 DeepMind's AlphaGo program, powered by a deep neural network, beats Lee Sodol, the world champion Go player, in a five-game match. The victory is significant given the huge number of possible moves as the game progresses (over 14.5 trillion after just four moves). Later, Google purchased DeepMind for a reported USD 400 million. 2022 A rise in large language models or LLMs, such as OpenAI’s ChatGPT, creates an enormous change in performance of AI and its potential to drive enterprise value. With these new generative AI practices, deep-learning models can be pretrained on large amounts of data. 2024 The latest AI trends point to a continuing AI renaissance. Multimodal models that can take multiple types of data as input are providing richer, more robust experiences. These models bring together computer vision image recognition and NLP speech recognition capabilities. Smaller models are also making strides in an age of diminishing returns with massive models with large parameter counts. Ebook How to choose the right foundation model Learn how to choose the right approach in preparing datasets and employing foundation models. Read the ebook",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Related solutions IBM watsonx.ai Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data. Discover watsonx.ai Artificial intelligence solutions Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions AI consulting and services Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value. Explore AI services Take the next step Get one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs. Explore watsonx.ai Book a live demo",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Related solutions IBM watsonx.ai Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data. Discover watsonx.ai Artificial intelligence solutions Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions AI consulting and services Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value. Explore AI services Take the next step Get one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs. Explore watsonx.ai Book a live demo",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Related solutions IBM Maximo Visual Inspection Unleash the power of no-code computer vision for visual inspection automation. Explore Maximo Visual Inspection Artificial intelligence (AI) consulting and services IBM consulting AI services help reimagine how businesses work with AI for transformation. Explore artificial Intelligence services Artificial intelligence solutions Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions Take the next step IBM Maximo Visual Inspection puts the power of computer vision AI capabilities into the hands of your quality control and inspection teams. Unleash the power of no-code computer vision for visual inspection automation. Explore Maximo Visual Inspection Take a product tour Footnotes 1. Emerging Tech: Revenue Opportunity Projection of Computer Vision: Growth Markets, Gartner, April 19, 2024. 2. https://hackernoon.com/a-brief-history-of-computer-vision-and-convolutional-neural-networks-8fe8aacc79f3 3. Optical character recognition, Wikipedia 4. Intelligent character recognition, Wikipedia 5. A Brief History of Computer Vision (and Convolutional Neural Networks), Rostyslav Demush, Hacker Noon, February 27, 2019 6. 7 Amazing Examples of Computer And Machine Vision In Practice, Bernard Marr, Forbes, April 8, 2019 7. The 5 Computer Vision Techniques That Will Change How You See The World, James Le, Heartbeat, April 12, 2018",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide",
  "Resources Report The 2025 CEO’s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms. Read the report AI models Explore IBM Granite IBM® Granite® is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report AI in Action 2024 We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide"
]